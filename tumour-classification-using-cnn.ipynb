{"cells":[{"metadata":{},"cell_type":"markdown","source":"**The cell below imports all the necessary packages required for this classification task**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dropout,Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Lambda\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nimport itertools\nfrom sklearn import metrics\nfrom keras.models import load_model\nimport os\nimport shutil\nfrom keras import backend as K\nimport random\nimport glob\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The below cell initialized the width, height of input images along with the directories for training and testing data, the batch size and number of epochs(iterations)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 64, 64\n\ntrain_data_dir = '../input/modiified/Modified_Dataset/Train'\ntest_data_dir = '../input/modiified/Modified_Dataset/Test'\nnb_train_samples = 1050\nnb_validation_samples = 144\nepochs = 50\nbatch_size = 32\n\nif K.image_data_format() == 'channels_first':\n    input_shape = (3, img_width, img_height)\nelse:\n    input_shape = (img_width, img_height, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This cell generates more training data by performing data augmentation, also performs data normalization by dividing them by 255**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.3,\n    zoom_range=0.3,\n    width_shift_range=0.25,\n    height_shift_range=0.25,\n    horizontal_flip=True,\n    vertical_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here the training and testing (here testing and validation are used as same) data batches are prepared by giving the directory to the data and other necessary parameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_batches = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    classes=['BENIGN', 'MALIGNANT', 'NORMAL'])\n    #color_mode=\"grayscale\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Same thing is performed as the training batch before**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_batches = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    classes=['BENIGN', 'MALIGNANT', 'NORMAL'])\n    #color_mode=\"grayscale\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here the Convolutional Neural Network model is built. You can use different number of layers,tune different value like dropout value from 0.5 to 0.6 or 0.25 or whatever value that may give the best result.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Just copy and paste the below cell block of three lines for an additional number of layer. You can change the value 32 to 64 or 128 or whatever value which may give the best output.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The Conv2D layers above are responsible for extracting the features and the layer below i.e the dense layers are responsible to perform the classification. Simillarly, you can change the number of nodes in the dense layer like 64 to 32, 128 or other desired values but the last layer must have nodes equal to the number of classes you are using,as in here it is 3.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.add(Flatten())\nmodel.add(Dense(64))\nmodel.add(Activation('relu'))\nmodel.add(Dense(128))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n#model.add(Dense(32))\n#model.add(Activation('relu'))\n\nmodel.add(Dense(3))\nmodel.add(Activation('softmax'))\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This cell below performs the training. The callback function is used to stop the training when no improvement occurs.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nh = model.fit(\n    train_batches,\n    steps_per_epoch=nb_train_samples // batch_size,\n    epochs=epochs,\n    validation_data=test_batches,\n    validation_steps=nb_validation_samples // batch_size,\n    callbacks=[\n        #tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4),\n        tf.keras.callbacks.ModelCheckpoint(filepath = '/kaggle/working/Model_{val_accuracy:.3f}.h5', save_best_only=True,\n                                          save_weights_only=False, monitor='val_accuracy')\n    ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The true label for test images are loaded here and processed necessarily.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_batches = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=144,\n    classes=['BENIGN', 'MALIGNANT', 'NORMAL'])\n    #color_mode=\"grayscale\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs, test_labels = next(test_batches)\nrounded_labels = np.argmax(test_labels, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The best performing model is loaded here.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_model = load_model('./Model_0.797.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here the prediction is performed.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = test_model.predict(test_batches, steps=1, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rounded_prediction = np.argmax(predictions, axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in rounded_prediction:\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**The confusion matrix shows the result of the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_true=rounded_labels, y_pred=rounded_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm_plot_labels = ['BENIGN', 'MALIGNANT', 'NORMAL']\nplot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='confusion_matrix')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_true=rounded_labels, y_pred=rounded_prediction))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This is the accuracy curve**"},{"metadata":{"trusted":true},"cell_type":"code","source":"accs = h.history['accuracy']\nval_accs = h.history['val_accuracy']\n\nplt.plot(range(len(accs)),accs, label = 'Training_accuracy')\nplt.plot(range(len(accs)),val_accs, label = 'Testing_accuracy')\nplt.xlabel('x-axis (no.of epoch)')\nplt.ylabel('y-axis (accuracy_value)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This is the loss curve.These accuracy and loss curves only generate when the training is performed. If just load a pre-trained best performing model without training the model then running thses cells will generate error.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"accs = h.history['loss']\nval_accs = h.history['val_loss']\n\nplt.plot(range(len(accs)),accs, label = 'Training_loss')\nplt.plot(range(len(accs)),val_accs, label = 'Testing_loss')\nplt.xlabel('x-axis (no.of epoch)')\nplt.ylabel('y-axis (loss_value)')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here necessary functions are defined to load a single image to perform the prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom skimage import transform\ndef load(filename):\n    img = Image.open(filename)\n    img = np.array(img).astype('float32')/255\n    img = transform.resize(img, (64, 64, 3))\n    img = np.expand_dims(img, axis=0)\n    return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Here the image is loaded and prediction is performed. Enter the path of the desired image below inside the ('  ')**"},{"metadata":{"trusted":true},"cell_type":"code","source":"image = load('../input/modiified/Modified_Dataset/Test/MALIGNANT/10.jpg')\nprediction = test_model.predict(image)\nprediction","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This cell block will give the predicted output**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rounded_prediction = np.argmax(prediction, axis=-1)\nif rounded_prediction == 0:\n    print(\"Benign\")\nelif rounded_prediction == 1:\n    print(\"Malignant\")\nelif rounded_prediction == 2:\n    print(\"Normal\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}